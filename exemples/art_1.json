{
    "abstract": "Scientific workflows are a de facto standard for modeling scientific experiments. However, several workflows have too many parameters to be manuallyconfigured. Poor choices of parameter values may lead to unsuccessful executionsof the workflow. In this paper, we present F ReeP, a parameter recommendation algorithm that suggests a value to a parameter that agrees with the user preferences.F ReeP is based on the Preference Learning technique. A preliminary experimentalevaluation performed over the SciPhy workflow showed the feasibility of F ReeP torecommend parameter values for scientific workflows.",
    "1. Introduction": " Scientific workflows are considered a de facto standard for modeling scientific experimentsthat are compute- and data-intensive [Zhao et al. 2008]. They are abstractions that representthe flow of data among activities (i.e., program invocations). The Scientific Workflow Management Systems (SWfMS) are responsible for managing the execution of workflows andcollecting provenance data [Freire et al. 2008], which represent the execution history of theworkflow. A workflow can be formally defined as a directed acyclic graph W(A, Dep). Thenodes A = {@1,d2, ..., @,} are the activities and the edges Dep represent the data dependencies among activities in A. Thus, given a; | (1 <i < n), the set P = {p1,po,..,Dm}represents the possible input parameters for activity a, that define the behavior of a;. Scientific Workflows are applied in many fields, such as biology and astronomy. G1ven the increasingly complexity of experiments in these domains [Zhao et al. 2008], manyworkflows have many parameters to be configured by users (e.g., > 40). The configuration ofsuch parameters is a sensitive point because it can impact the execution time of the workflowand the usefulness of the produced results. This way, it is required that the user is able toconfigure the workflow (e.g., setting values for all the m parameters of an activity a;) as bestas possible. Let us take as an example the workflow SciPhy [Ocajfia et al. 2011]. SciPhy aimsat generating phylogenetic trees (i.e., trees that represent the evolutionary history of an organism). It is composed of four activities: (1) sequence alignment; (11) conversion of alignmentformat; (111) search for the best evolutionary model; and (iv) construction of the phylogenetictree. Although conceptually simple (i.e., it has only four activities), SciPhy can be complex tobe configured because of the number of parameters that should be explored. In addition, theuser does not necessarily know a priori which configuration generates the best-quality phylogenetic tree. For example, each input file that contains DNA or RNA sequences has a number * Authors would like to thank FAPERJ, CAPES and CNPg for partially sponsoring this research of sequences num_seqg and a maximum length of sequence length_seq, which are input parameters of activity (i). However, to activity (iv) the input parameter bootstrap_replicate hasits utility limited depending on the choice of values for length_seq. A poor choice of suchvalues can generate a worthless result (in addition to the loss of time and resources). Thus, it is interesting that the parameter values can be automatically recommended tousers by a Recommendation System (RS) to increase the chances of producing good results.For example, if in a given SciPhy execution the user sets the value of num_seq = 100, itwould be better that the value of bootstrap_replicate to be recommended by an RS followedthe value of num_seq in order to avoid incompatibility of the parameter values. This type ofrecommendation is feasible, since the SWfMSs collect provenance data, but it is not simple tobe performed. Provenance can be used for future recommendations as we know which executions produced successful results and which parameter values were used. The motivation of this paper 1s, therefore, to recommend parameter values of workflow activities using provenance data collected in previous workflow executions. Thus, we propose a parameter recommendation algorithm named F’ Ree FP for scientific workflows that benefits from the other chosen parameters. This way, F'ReeP is able to suggest a value to a set of parameters that agreeswith the user preferences. To accommodate such preferences together with the more appropriate recommendation, we follow a Preference Learning [Firnkranz and Hiillermeier 2011]technique. The experimental evaluation performed with the SciPhy workflow showed thefeasibility of f ReeP to recommend parameter values. Recommendation algorithms aim at suggesting the most relevant items to solve a task thatrequires a choice. In a personalized recommendation, each user receives his/her own listof items, based on his/her preferences. From the Artificial Intelligence point of view, apreference is an expression of the problem’s constraints, but allowing some sort of relaxation [Fiirnkranz and Hiillermeier 2011]. In general, Preference Learning consists of inducinga predictive function that, given a set of already established-as-preferred items, it predicts thepreferences for a new set of items. The most likely research task in this area is \"Learning howto rank\", rising from the need of obtaining an ordering relation among the preferences. Theordering task may focus on the class label, directly on the instances, or on a subsect of theobjects. Particularly, one of the most used technique to learn preferences is Pairwise LabelRanking [Hillermeier et al. 2008]. It consists of learning the preferences by decomposingthe problem in smaller binary preferences problems, i.e., preferences between pairs of classes. Next, an ordering is induced relying on methods that minimize the loss function. Thisfunction, in turn, is computed according to the preferences that are violated, considering eachdifferent combination of classes.",
    "3. FReeP: Feature Recommender from Preferences": " In this paper, we propose a recommendation algorithm named F'ReeFP that relies on provenance data, preference learning, and voting systems to recommend a value for a specifiedparameter. The recommendation provided by F'ReeP is the combination of a set of selected recommendations. These recommendations are created according to other specified parameter values. Ff’ ReeP belongs to the category of Collaborative Filtering [Herlocker et al. 2004]methods and is presented in Algorithm 1. Algorithm 1 FReePRequire: 1: S: { (paramt, valt),...(param)™, val;”) } © lis the number of workflow parameters and m is the numberof tuples in the provenance database2: F: {attr | attr is a workflow parameter }3: C: {attr_preference | attr_preference € F}defined a value 4: f(attr) : {preference_value | attr eC} > preference_value is the value defined by user for parameter attr5: P: {(attr,attr_preference) | attr € C A attr_preference € f(attr)} y | y € (F- C)6: procedure FREEP(type) > Type is used to select between pure KNN or Label Rank7: votes <— ); FS <— POWER_SET(C) \\ § > POWERSET it the math operation that returns the set of all to_recommend < {attr_pre ference | (attr, attr_preference) € P, attr € set}: vote <- RECOMMEND(to_recommend, recommender, type) > KNN returns the predicted value,while LabelRank returns the results of the ranking process| votes <— votes U {vote} 50: return recommendation To perform the parameter recommendation we rely on the tuples extracted from theProvenance database S. These tuples represent successful executions of a given workflow.The set of preferences P, i.e., the parameters for which the scientist already has a set of values, and the parameter to be recommended y are also provided as input to F'ReeP. Thefirst step is to create the set of all subsets of the instances (the power set)!, grounded bythe preferred parameters, called F’'S. For each subset of F'S a horizontal partition is performed over the provenance data, by selecting only the tuples where each parameter (i.e.,attribute) has the same value as specified in the user preferences. Next, only the attributesof the tuples that represent the parameters present in the user preferences are gathered (i.e.,vertical partition). After that, the algorithm may follow two paths: either it uses a KNN classifier [Cover and Hart 1967], or a LabelRank [Hillermeier et al. 2008] classifier. Both of themuse the aforementioned partitions to make the recommendation for the parameter y. If thechoice is KNN, the prediction model is trained with the data in the partition and their respective values for the y parameter, yielding the prediction of values for the other parameter in thepartition and stated in the user preferences. On the other hand, if the choice is LabelRank, aranking function is trained in the same way as the KNN, however, it returns a sorted list, fromthe most appropriate value for y to the least one. In this paper, we choose to use the PairwiseLabel Ranking method to approximate the ranking function. Each partition generates a possibly different recommendation to the y parameter. Thisimplies in combining the different recommendations in order to arrive at a consensus of whatitis the best one. When the chosen method is KNN, the recommendation for each partition is asingle value, resulting in a list of recommended values. In this case, we use the Simple VotingSystem [Fishburn 1974] where the value that is most cited among the recommendations is theselected one. On the other hand, the LabelRank method returns the recommendations as aranking. The result after the interaction at each partition is a list of rankings. Here, we couldalso employ a simple voting system based on the value ranked as the first one. However,this would neglect other well-ranked values among the different partitions. Thus, we use theBorder Count method [Black 1976] that combines all rankings into one, after giving scoresfor each parameter value according to its position in each ranking. After that, we use thehighest ranking value as the final recommendation.",
    "4. Experimental Results": " To evaluate F'ReeP, we used the provenance data collected by SciCumulus SWfMS whenexecuting SciPhy workflow [Ocafia et al. 2011]. SciPhy was developed to build phylogenetictrees from DNA, RNA and amino acid sequences. The dataset used to train de Machine Learning models is composed of 376 examples of executions that have not ended at a failure. Wefollow a 5-Fold Cross Validation procedure [Refaeilzadeh et al. 2016], dividing the examplesinto 5 disjoint sets, and, at each iteration, 4 sets were used to train the models, while theremaining set was used as test. We considered kK € [3,5,7] in both pure KNN and LabelRank methods. We experiment with the recommendation of each parameter of the workflow,separately. We compute the accuracy of both models to evaluate the capability of both approaches in suggesting the right value parameter. Figure 4 shows the experimental results. Wecan see a clear difference in the accuracies between the recommendation for the parameternum_aligns and all the others. While for the first the recommendation reached values greater than 90%, the others reached accuracies varying from 40% to 60%. This can be explained ‘Tn this initial version, we follow the most basic way of choosing the subsets by using the powerset of theoriginal data. This may lead to an exponential number of partitions. by the smaller variation of values for the parameter num_aligns in the input dataset. Different values of the AK parameter did not lead to significant changes in the recommendations,with low standard deviation among the folds. Furthermore, the rank-based model obtained worse results than KNN. Although theyboth come close regarding the parameters num_aligns, model_1, and model_2, the rankaccuracy results for the rest of the parameters are close to zero. One explanation for suchbehavior is the numerical nature of these attributes and their very sparse values in the inputdataset, which produces very different rankings along the training.",
    "5. Related Work": " The ranking strategy used in this paper was also used in the recommendation context but applied to movies scenario [Pessiot et al. 2007]. The voting method has been used to decreasethe training time with large datasets in a movies recommendation task, without deteriorating the quality of the recommendation [Das et al. 2014, Mukherjee et al. 2003]. Particularly, in [Mukherjee et al. 2003], Preference Learning is also used to leverage the recommendation. Regarding recommendation in workflows, Halioui [Halioui et al. 2016] combined natural language processing with ontologies to recommend searching keywords. In[Soomro et al. 2015], a pattern-based recommendation approach was built to suggest workflows composition. [Cheng et al. 2015] propose an approach for identifying and recommending the workflows for reference using semantic similarity. However, the aforementionedapproaches do not recommend values to the parameters.",
    "6. Conclusions and Future Work": " The effective use of scientific workflows and SWfMS have fostered the scientific experimentation and its analysis. However, several experiments modeled as workflows have a large setof parameters to be configured, which is not a trivial task to accomplish. While in some casesthe scientist may be working on an experiment where he/she already knows at least a subsetof the most appropriate values, he/she may not know which is the best values to assign tothe others parameters of the workflow. In addition, a poor choice of parameters may lead toundesired results and loss of time. In this paper, we propose a parameter recommendationalgorithm called F’'ReeP, based on Preference Learning and Voting Systems to recommendvalues for parameters, while restraining the recommendations to the user preferences. Experiments showed that when we employ a KNN classifier we can reach the correct parametervalue in most cases, even in the presence of a reduced training set. On the other hand, we still need to improve the methods based on LabelRank so that it can achieve its full potential.As future work, we plan: (1) to consider more clever partition strategies to make the trainingmore efficient; (11) to rely on a non-uniform choice from the KNN classifier; (411) to exploreother classifiers; and (iv) to test other voting schemas. Black, D. (1976). Partial justification of the borda count. Public Choice, 28(1):1-15. Cheng, Z., Zhou, Z., and Wang, X. (2015). Scientific workflow clustering and recommendation. In //th International Conf. on Semantics, Knowledge and Grids (SKG), pages Cover, T. and Hart, P. (1967). Nearest neighbor pattern classification. JEEE transactions oninformation theory, 13(1):21-27. Das, J., Mukherjee, P., Majumder, S., and Gupta, P. (2014). Clustering-based recommendersystem using principles of voting theory. In /C3/, pages 230-235. IEEE. Fishburn, P. C. (1974). Simple voting systems and majority rule. Systems Research andBehavioral Science, 19(3):166—-176. Freire, J., Koop, D., Santos, E., and Silva, C. T. (2008). Provenance for Computational Tasks:A Survey. Computing in Science & Engineering, pages 20-30. Fiirnkranz, J. and Hiillermeier, E. (2011). Preference learning. In Encyclopedia of MachineLearning, pages 789-795. Springer. Halioui, A., Valtchev, P., and Diallo, A. B. (2016). Towards an ontology-based recommendersystem for relevant bioinformatics workflows. bioRxiv, page 082776. Herlocker, J. L., Konstan, J. A., Terveen, L. G., and Riedl, J. T. (2004). Evaluating collaborative filtering recommender systems. ACM Trans. Inf. Syst., 22(1):5—53. Hiillermeier, E., Fiirnkranz, J., Cheng, W., and Brinker, K. (2008). Label ranking by learningpairwise preferences. Artificial Intelligence, 172(16-17):1897-1916. Mukherjee, R., Sajja, N., and Sen, S. (2003). A movie recommendation system—an application of voting theory in user modeling. User Modeling and User-Adapted Interaction,13(1-2):5-33. Ocafia, K. A., de Oliveira, D., Ogasawara, E., Davila, A. M., Lima, A. A., and Mattoso,M. (2011). Sciphy: a cloud-based workflow for phylogenetic analysis of drug targets inprotozoan genomes. In BSB//, pages 66—70. Springer. Pessiot, J., Truong, T., Usunier, N., Amini, M., and Gallinari, P. (2007). Learning to rank forcollaborative filtering. In JCEIS 2007 - Proc. of the 9th International Conf. on Enterprise Refaeilzadeh, P., Tang, L., and Liu, H. (2016). Cross-validation. Encyclopedia of databasesystems, pages 1-7. Soomro, K., Munir, K., and McClatchey, R. (2015). Incorporating semantics in pattern-basedscientific workflow recommender systems: Improving the accuracy of recommendations.In SAI’2015, pages 565-571. IEEE. Zhao, Y., Raicu, I., and Foster, I. (2008). Scientific workflow systems for 21st century, newbottle or new wine? In JEEEF Services, pages 467-471. IEEE."
}